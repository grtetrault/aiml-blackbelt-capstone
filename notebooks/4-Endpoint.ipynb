{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8667a16b",
   "metadata": {},
   "source": [
    "# 4 - Endpoint <a class=\"anchor\" id=\"top\"></a>\n",
    "* [Introduction](#intro)\n",
    "* [Setup](#setup)\n",
    "* [Define and deploy the model](#define)\n",
    "* [Productionize the endpoint](#prod)\n",
    "    * [Autoscaling](#autoscale)\n",
    "    * [Model monitor](#monitor)\n",
    "* [Testing the endpoint](#test)\n",
    "* [Cleanup resources](#cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3dfa54",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "In this last section, we create a Sagemaker endpoint to allow for real-time predictions using our trained models.\n",
    "After creating the endpoint, we will test a simple application that takes in basic flight information and returns \n",
    "the models prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3a5c3",
   "metadata": {},
   "source": [
    "## Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "First, we import Sageamker SDK dependencies as well as modules used in application below.\n",
    "We also get relevant sessions and read in local environment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fee10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml\n",
    "import json\n",
    "import uuid\n",
    "import boto3\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import dateutil.parser\n",
    "import sagemaker as sm\n",
    "import sagemaker.sparkml as sparkml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e47ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get relevant sessions.\n",
    "sm_session = sm.Session()\n",
    "role = sm.get_execution_role()\n",
    "boto3_session = boto3.session.Session()\n",
    "now = dt.datetime.now().strftime(r\"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddaf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boto3 session attributes.\n",
    "account = boto3_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3_session.region_name\n",
    "s3_resource = boto3_session.resource(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "530c1198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data bucket name.\n",
    "with open(\"/home/ec2-user/.aiml-bb/stack-data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    data_bucket = data[\"data_bucket\"]\n",
    "    model_bucket = data[\"model_bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c107d",
   "metadata": {},
   "source": [
    "## Define and deploy the model <a class=\"anchor\" id=\"define\"></a>\n",
    "To allow for a complete inference pipeline, we chain together the preprocessing, model inference/evaluation, and postprocessing.\n",
    "We will define each of these stages as a Sagemaker `Model` object, then chain them together into an inference pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9c2280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required schema for input into preprocessing step.\n",
    "preprocess_schema_json = json.dumps({\n",
    "    \"input\": [\n",
    "        {\"name\": \"day_of_week\", \"type\": \"int\"},\n",
    "        {\"name\": \"month\", \"type\": \"int\"},\n",
    "        {\"name\": \"op_carrier\", \"type\": \"string\"},\n",
    "        {\"name\": \"origin_latitude\", \"type\": \"double\"}, \n",
    "        {\"name\": \"origin_longitude\", \"type\": \"double\"},\n",
    "        {\"name\": \"dest_latitude\", \"type\": \"double\"}, \n",
    "        {\"name\": \"dest_longitude\", \"type\": \"double\"},\n",
    "        {\"name\": \"origin_tmax\", \"type\": \"double\"}, \n",
    "        {\"name\": \"origin_tmin\", \"type\": \"double\"}, \n",
    "        {\"name\": \"origin_prcp\", \"type\": \"double\"}, \n",
    "        {\"name\": \"origin_snow\", \"type\": \"double\"}, \n",
    "        {\"name\": \"origin_snwd\", \"type\": \"double\"},\n",
    "        {\"name\": \"dest_tmax\", \"type\": \"double\"}, \n",
    "        {\"name\": \"dest_tmin\", \"type\": \"double\"}, \n",
    "        {\"name\": \"dest_prcp\", \"type\": \"double\"}, \n",
    "        {\"name\": \"dest_snow\", \"type\": \"double\"}, \n",
    "        {\"name\": \"dest_snwd\", \"type\": \"double\"}\n",
    "    ],\n",
    "     \"output\": {\"name\": \"features\", \"type\": \"double\", \"struct\": \"vector\"}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf44962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing model.\n",
    "preprocess_model = sparkml.model.SparkMLModel(\n",
    "    name=f\"spark-preprocessor-{now}\",\n",
    "    model_data=f\"s3://{model_bucket}/spark-preprocessor/model.tar.gz\",\n",
    "    spark_version=\"2.4\",\n",
    "    sagemaker_session=sm_session,\n",
    "    env={\"SAGEMAKER_SPARKML_SCHEMA\": preprocess_schema_json}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4021026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define inference model using XGBoost, \n",
    "# the best performing model.\n",
    "xgb_container_image = sm.image_uris.retrieve(\"xgboost\", region, \"latest\")\n",
    "xgb_inference_model = sm.model.Model(\n",
    "    image_uri=xgb_container_image,\n",
    "    model_data=f\"s3://{model_bucket}/sagemaker-xgboost-tuned/model.tar.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0446eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define complete inference pipeline model.\n",
    "pipeline_model = sm.pipeline.PipelineModel(\n",
    "    name=f\"sm-pipeline-{now}\",\n",
    "    role=role,\n",
    "    models=[\n",
    "        preprocess_model,\n",
    "        xgb_inference_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbe50882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "# Enable data capture and create endpoint.\n",
    "endpoint_name = f\"pipeline-endpoint-{now}\"\n",
    "data_capture_config = sm.model_monitor.DataCaptureConfig(\n",
    "    enable_capture=True,\n",
    "    sampling_percentage=100,\n",
    "    destination_s3_uri=f\"s3://{model_bucket}/endpoint-data-capture/{endpoint_name}/\"\n",
    ")\n",
    "pipeline_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    data_capture_config=data_capture_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19214124",
   "metadata": {},
   "source": [
    "## Productionize the endpoint <a class=\"anchor\" id=\"prod\"></a>\n",
    "We now ready the model for production by adding autoscaling to ensure high availability and a Model Monitor to continuously track the quality of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e346b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary resources.\n",
    "autoscaling_client = boto3.client(\"application-autoscaling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5364c1",
   "metadata": {},
   "source": [
    "### Autoscaling <a class=\"anchor\" id=\"autoscale\"></a>\n",
    "Attach a CPU base autoscaling policy that triggers on high CPU utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56a2aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the endpoint for autoscaling.\n",
    "endpoint_resource_id=f\"endpoint/{endpoint_name}/variant/AllTraffic\"\n",
    "register_scalable_target_response = autoscaling_client.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=endpoint_resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2 # Low for testing purposes.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02513fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a CPU based autoscaling policy.\n",
    "autoscaling_policy_name = f\"CPUUtil-ScalingPolicy\"\n",
    "put_scaling_policy_response = autoscaling_client.put_scaling_policy(\n",
    "    PolicyName=autoscaling_policy_name,\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=endpoint_resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 90.0,\n",
    "        \"CustomizedMetricSpecification\":\n",
    "        {\n",
    "            \"MetricName\": \"CPUUtilization\",\n",
    "            \"Namespace\": \"/aws/sagemaker/Endpoints\",\n",
    "            \"Dimensions\": [\n",
    "                {\"Name\": \"EndpointName\", \"Value\": endpoint_name },\n",
    "                {\"Name\": \"VariantName\",\"Value\": \"AllTraffic\"}\n",
    "            ],\n",
    "            \"Statistic\": \"Average\",\n",
    "            \"Unit\": \"Percent\"\n",
    "        },\n",
    "        \"ScaleInCooldown\": 600,\n",
    "        \"ScaleOutCooldown\": 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9bbd9",
   "metadata": {},
   "source": [
    "### Model monitor <a class=\"anchor\" id=\"monitor\"></a>\n",
    "Create a model quality monitor baselined against the validation data set. \n",
    "Note that we are only modelling the inference step in our model pipeline, excluding the preprocessing step.\n",
    "This is so we can baseline against our already preprocessed data as well as isolate inference performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model monitor and baseline against validation data.\n",
    "inference_model_monitor = sm.model_monitor.DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600\n",
    ")\n",
    "inference_model_monitor.suggest_baseline(\n",
    "    baseline_dataset=f\"s3://{data_bucket}/preprocessing_output/baseline/\",\n",
    "    dataset_format=sm.model_monitor.dataset_format.DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=f\"s3://{model_bucket}/inference-model-monitor/\",\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b5827be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.model_monitor.model_monitoring.BaseliningJob at 0x7fd00c094198>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_baselining_job = inference_model_monitor.latest_baselining_job\n",
    "latest_baselining_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9275350d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>numerical_statistics.common.num_present</th>\n",
       "      <th>numerical_statistics.common.num_missing</th>\n",
       "      <th>numerical_statistics.mean</th>\n",
       "      <th>numerical_statistics.sum</th>\n",
       "      <th>numerical_statistics.std_dev</th>\n",
       "      <th>numerical_statistics.min</th>\n",
       "      <th>numerical_statistics.max</th>\n",
       "      <th>numerical_statistics.distribution.kll.buckets</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.c</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.parameters.k</th>\n",
       "      <th>numerical_statistics.distribution.kll.sketch.data</th>\n",
       "      <th>string_statistics.common.num_present</th>\n",
       "      <th>string_statistics.common.num_missing</th>\n",
       "      <th>string_statistics.distinct_count</th>\n",
       "      <th>string_statistics.distribution.categorical.buckets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499990</td>\n",
       "      <td>9.297209e+06</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [1.0], [1.0], [1.0], [], [1.0], [1.0], [1...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>Integral</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.930799</td>\n",
       "      <td>7.309241e+07</td>\n",
       "      <td>1.988336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 1.6, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [7.0], [7.0], [7.0], [], [7.0], [7.0], [7...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>Integral</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.373626</td>\n",
       "      <td>1.185163e+08</td>\n",
       "      <td>3.371035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>[{'lower_bound': 1.0, 'upper_bound': 2.1, 'cou...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [12.0], [12.0], [12.0], [], [12.0], [12.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>op_carrier</td>\n",
       "      <td>String</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>[{'value': 'DL', 'count': 2276123}, {'value': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>origin_latitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.705290</td>\n",
       "      <td>6.825275e+08</td>\n",
       "      <td>5.829150</td>\n",
       "      <td>-14.331000</td>\n",
       "      <td>71.285402</td>\n",
       "      <td>[{'lower_bound': -14.3310003281, 'upper_bound'...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [64.81510162], [64.81510162], [64.8151016...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>origin_longitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.698524</td>\n",
       "      <td>-1.760900e+09</td>\n",
       "      <td>17.936394</td>\n",
       "      <td>-170.710007</td>\n",
       "      <td>145.729004</td>\n",
       "      <td>[{'lower_bound': -170.710006714, 'upper_bound'...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [-64.79859924316406], [-64.79859924316406...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dest_latitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.709299</td>\n",
       "      <td>6.826020e+08</td>\n",
       "      <td>5.859106</td>\n",
       "      <td>-14.331000</td>\n",
       "      <td>71.285402</td>\n",
       "      <td>[{'lower_bound': -14.3310003281, 'upper_bound'...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [61.17440032958984], [71.285402], [61.174...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dest_longitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-94.802398</td>\n",
       "      <td>-1.762831e+09</td>\n",
       "      <td>18.110998</td>\n",
       "      <td>-170.710007</td>\n",
       "      <td>145.729004</td>\n",
       "      <td>[{'lower_bound': -170.710006714, 'upper_bound'...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [-66.0018005371], [144.796005249], [-66.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>origin_tmax</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.662616</td>\n",
       "      <td>4.010203e+09</td>\n",
       "      <td>107.342548</td>\n",
       "      <td>-733.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>[{'lower_bound': -733.0, 'upper_bound': -599.7...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [467.0], [461.0], [467.0, 461.0, 461.0, -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>origin_tmin</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>18594798.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113.047247</td>\n",
       "      <td>2.102091e+09</td>\n",
       "      <td>101.181620</td>\n",
       "      <td>-733.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>[{'lower_bound': -733.0, 'upper_bound': -599.7...</td>\n",
       "      <td>0.64</td>\n",
       "      <td>2048.0</td>\n",
       "      <td>[[], [328.0], [339.0], [317.0, 333.0, 328.0, -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name inferred_type  numerical_statistics.common.num_present  \\\n",
       "0            target    Fractional                               18594798.0   \n",
       "1       day_of_week      Integral                               18594798.0   \n",
       "2             month      Integral                               18594798.0   \n",
       "3        op_carrier        String                                      NaN   \n",
       "4   origin_latitude    Fractional                               18594798.0   \n",
       "5  origin_longitude    Fractional                               18594798.0   \n",
       "6     dest_latitude    Fractional                               18594798.0   \n",
       "7    dest_longitude    Fractional                               18594798.0   \n",
       "8       origin_tmax    Fractional                               18594798.0   \n",
       "9       origin_tmin    Fractional                               18594798.0   \n",
       "\n",
       "   numerical_statistics.common.num_missing  numerical_statistics.mean  \\\n",
       "0                                      0.0                   0.499990   \n",
       "1                                      0.0                   3.930799   \n",
       "2                                      0.0                   6.373626   \n",
       "3                                      NaN                        NaN   \n",
       "4                                      0.0                  36.705290   \n",
       "5                                      0.0                 -94.698524   \n",
       "6                                      0.0                  36.709299   \n",
       "7                                      0.0                 -94.802398   \n",
       "8                                      0.0                 215.662616   \n",
       "9                                      0.0                 113.047247   \n",
       "\n",
       "   numerical_statistics.sum  numerical_statistics.std_dev  \\\n",
       "0              9.297209e+06                      0.500000   \n",
       "1              7.309241e+07                      1.988336   \n",
       "2              1.185163e+08                      3.371035   \n",
       "3                       NaN                           NaN   \n",
       "4              6.825275e+08                      5.829150   \n",
       "5             -1.760900e+09                     17.936394   \n",
       "6              6.826020e+08                      5.859106   \n",
       "7             -1.762831e+09                     18.110998   \n",
       "8              4.010203e+09                    107.342548   \n",
       "9              2.102091e+09                    101.181620   \n",
       "\n",
       "   numerical_statistics.min  numerical_statistics.max  \\\n",
       "0                  0.000000                  1.000000   \n",
       "1                  1.000000                  7.000000   \n",
       "2                  1.000000                 12.000000   \n",
       "3                       NaN                       NaN   \n",
       "4                -14.331000                 71.285402   \n",
       "5               -170.710007                145.729004   \n",
       "6                -14.331000                 71.285402   \n",
       "7               -170.710007                145.729004   \n",
       "8               -733.000000                600.000000   \n",
       "9               -733.000000                600.000000   \n",
       "\n",
       "       numerical_statistics.distribution.kll.buckets  \\\n",
       "0  [{'lower_bound': 0.0, 'upper_bound': 0.1, 'cou...   \n",
       "1  [{'lower_bound': 1.0, 'upper_bound': 1.6, 'cou...   \n",
       "2  [{'lower_bound': 1.0, 'upper_bound': 2.1, 'cou...   \n",
       "3                                                NaN   \n",
       "4  [{'lower_bound': -14.3310003281, 'upper_bound'...   \n",
       "5  [{'lower_bound': -170.710006714, 'upper_bound'...   \n",
       "6  [{'lower_bound': -14.3310003281, 'upper_bound'...   \n",
       "7  [{'lower_bound': -170.710006714, 'upper_bound'...   \n",
       "8  [{'lower_bound': -733.0, 'upper_bound': -599.7...   \n",
       "9  [{'lower_bound': -733.0, 'upper_bound': -599.7...   \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.c  \\\n",
       "0                                               0.64           \n",
       "1                                               0.64           \n",
       "2                                               0.64           \n",
       "3                                                NaN           \n",
       "4                                               0.64           \n",
       "5                                               0.64           \n",
       "6                                               0.64           \n",
       "7                                               0.64           \n",
       "8                                               0.64           \n",
       "9                                               0.64           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.parameters.k  \\\n",
       "0                                             2048.0           \n",
       "1                                             2048.0           \n",
       "2                                             2048.0           \n",
       "3                                                NaN           \n",
       "4                                             2048.0           \n",
       "5                                             2048.0           \n",
       "6                                             2048.0           \n",
       "7                                             2048.0           \n",
       "8                                             2048.0           \n",
       "9                                             2048.0           \n",
       "\n",
       "   numerical_statistics.distribution.kll.sketch.data  \\\n",
       "0  [[], [1.0], [1.0], [1.0], [], [1.0], [1.0], [1...   \n",
       "1  [[], [7.0], [7.0], [7.0], [], [7.0], [7.0], [7...   \n",
       "2  [[], [12.0], [12.0], [12.0], [], [12.0], [12.0...   \n",
       "3                                                NaN   \n",
       "4  [[], [64.81510162], [64.81510162], [64.8151016...   \n",
       "5  [[], [-64.79859924316406], [-64.79859924316406...   \n",
       "6  [[], [61.17440032958984], [71.285402], [61.174...   \n",
       "7  [[], [-66.0018005371], [144.796005249], [-66.0...   \n",
       "8  [[], [467.0], [461.0], [467.0, 461.0, 461.0, -...   \n",
       "9  [[], [328.0], [339.0], [317.0, 333.0, 328.0, -...   \n",
       "\n",
       "   string_statistics.common.num_present  string_statistics.common.num_missing  \\\n",
       "0                                   NaN                                   NaN   \n",
       "1                                   NaN                                   NaN   \n",
       "2                                   NaN                                   NaN   \n",
       "3                            18594798.0                                   0.0   \n",
       "4                                   NaN                                   NaN   \n",
       "5                                   NaN                                   NaN   \n",
       "6                                   NaN                                   NaN   \n",
       "7                                   NaN                                   NaN   \n",
       "8                                   NaN                                   NaN   \n",
       "9                                   NaN                                   NaN   \n",
       "\n",
       "   string_statistics.distinct_count  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                              21.0   \n",
       "4                               NaN   \n",
       "5                               NaN   \n",
       "6                               NaN   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "\n",
       "  string_statistics.distribution.categorical.buckets  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  [{'value': 'DL', 'count': 2276123}, {'value': ...  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistics on monitor baseline.\n",
    "latest_baselining_job = inference_model_monitor.latest_baselining_job\n",
    "schema_df = pd.json_normalize(\n",
    "    latest_baselining_job.baseline_statistics()\n",
    "    .body_dict[\"features\"]\n",
    ")\n",
    "schema_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "240b2354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>inferred_type</th>\n",
       "      <th>completeness</th>\n",
       "      <th>num_constraints.is_non_negative</th>\n",
       "      <th>string_constraints.domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>Integral</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>op_carrier</td>\n",
       "      <td>String</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[DL, F9, US, OO, 9E, B6, AA, YV, G4, EV, OH, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>origin_latitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>origin_longitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dest_latitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dest_longitude</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>origin_tmax</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>origin_tmin</td>\n",
       "      <td>Fractional</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name inferred_type  completeness  \\\n",
       "0            target    Fractional           1.0   \n",
       "1       day_of_week      Integral           1.0   \n",
       "2             month      Integral           1.0   \n",
       "3        op_carrier        String           1.0   \n",
       "4   origin_latitude    Fractional           1.0   \n",
       "5  origin_longitude    Fractional           1.0   \n",
       "6     dest_latitude    Fractional           1.0   \n",
       "7    dest_longitude    Fractional           1.0   \n",
       "8       origin_tmax    Fractional           1.0   \n",
       "9       origin_tmin    Fractional           1.0   \n",
       "\n",
       "  num_constraints.is_non_negative  \\\n",
       "0                            True   \n",
       "1                            True   \n",
       "2                            True   \n",
       "3                             NaN   \n",
       "4                           False   \n",
       "5                           False   \n",
       "6                           False   \n",
       "7                           False   \n",
       "8                           False   \n",
       "9                           False   \n",
       "\n",
       "                          string_constraints.domains  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3  [DL, F9, US, OO, 9E, B6, AA, YV, G4, EV, OH, N...  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View statistics on monitor baseline.\n",
    "constraints_df = pd.json_normalize(\n",
    "    latest_baselining_job.suggested_constraints()\n",
    "    .body_dict[\"features\"]\n",
    ")\n",
    "constraints_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bdc197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schedule to compare baseline against the realtime traffic.\n",
    "inference_model_monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=f\"inference-model-monitor-schedule\",\n",
    "    endpoint_input=endpoint_name,\n",
    "    statistics=inference_model_monitor.baseline_statistics(),\n",
    "    constraints=inference_model_monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=sm.model_monitor.CronExpressionGenerator.hourly(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d886be",
   "metadata": {},
   "source": [
    "## Testing the endpoint <a class=\"anchor\" id=\"test\"></a>\n",
    "Test the endpoint in a simple application where the flight information is inputted, and a prediction is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b1bd1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect a predictor to the endpoint.\n",
    "pipeline_predictor = sm.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sm_session,\n",
    "    serializer=sm.serializers.JSONSerializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a049d74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputted features.\n",
    "origin = \"JFK\"\n",
    "dest = \"LAX\"\n",
    "carrier = \"B6\"\n",
    "fl_date = \"2022-01-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d9a2ed",
   "metadata": {},
   "source": [
    "All code below would be abstracted away from the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a737038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get date attributes.\n",
    "today = dt.datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "fl_datetime = dt.datetime.strptime(fl_date, r\"%Y-%m-%d\")\n",
    "day_of_week = fl_datetime.weekday() + 1\n",
    "month = fl_datetime.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5001671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latitude and longitudes of airports.\n",
    "airport_df = pd.read_parquet(f\"s3://{data_bucket}/dl_output/airport_data\")\n",
    "get_iata_geolocation = (\n",
    "    lambda iata: \n",
    "    airport_df.loc[airport_df[\"iata\"]==iata, [\"latitude\", \"longitude\"]].iloc[0]\n",
    ")\n",
    "origin_lat, origin_lon = get_iata_geolocation(origin)\n",
    "dest_lat, dest_lon = get_iata_geolocation(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "907f7759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab weather data.\n",
    "forecast_fqdn = \"https://graphical.weather.gov\"\n",
    "get_geolocation_forecast = (\n",
    "    lambda lat, lon:\n",
    "    xml.etree.ElementTree.fromstring(\n",
    "        requests.get(\n",
    "            f\"{forecast_fqdn}/xml/SOAP_server/ndfdXMLclient.php\",\n",
    "            params={\n",
    "                \"lat\": lat, \"lon\": lon,\n",
    "                \"begin\": today.isoformat(), \n",
    "                \"end\": (today + dt.timedelta(days=7)).isoformat(),\n",
    "                \"Unit\": \"m\",\n",
    "                \"maxt\": \"maxt\", \"mint\": \"mint\",\n",
    "                \"qpf\": \"qpf\", \"snow\": \"snow\",\n",
    "                \"product\": \"time-series\",\n",
    "                \"Submit\": \"Submit\"\n",
    "            }\n",
    "        ).content\n",
    "    )\n",
    ")\n",
    "origin_forecast = get_geolocation_forecast(origin_lat, origin_lon) \n",
    "dest_forecast = get_geolocation_forecast(dest_lat, dest_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6659a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get averages of date values in XML.\n",
    "def get_avg_xml_value(xml_tree, field, datetime=fl_datetime):\n",
    "    # Get date index key.\n",
    "    layout_key = xml_tree.find(f\".//*{field}\").attrib[\"time-layout\"]\n",
    "    \n",
    "    # Find indices of dates matching date in question.\n",
    "    idxs = []\n",
    "    for idx, date in enumerate(xml_tree.findall(f\".//*time-layout/start-valid-time\")):\n",
    "        datetime = dateutil.parser.parse(date.text)\n",
    "        if fl_datetime.strftime(\"%Y-%m-%d\") == datetime.strftime(\"%Y-%m-%d\"):\n",
    "            idxs.append(idx)\n",
    "            \n",
    "    if not idxs:\n",
    "        raise ValueError(\"Date invalid, no data found for field. Possibly too far into the future.\")\n",
    "            \n",
    "    # Data is for different times of day so we take mean.\n",
    "    # Zero is added so we default in case of no data (e.g. with snow).\n",
    "    val_sum = 0.0\n",
    "    for idx, val in enumerate(xml_tree.findall(f\".//*{field}/value\")):\n",
    "        if idx in idxs:\n",
    "            val_sum += float(val.text)\n",
    "            \n",
    "    return val_sum / len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13a7ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get forecast values and convert to dataset formats.\n",
    "# In NOAA weather data, all values are scaled by 1/10.\n",
    "origin_tmax = 0.10 * get_avg_xml_value(origin_forecast, \"temperature[@type='maximum']\")\n",
    "origin_tmin = 0.10 * get_avg_xml_value(origin_forecast, \"temperature[@type='minimum']\")\n",
    "origin_snwd = 0.10 * get_avg_xml_value(origin_forecast, \"precipitation[@type='snow']\")\n",
    "origin_liquid = 0.10 * get_avg_xml_value(origin_forecast, \"precipitation[@type='liquid']\")\n",
    "\n",
    "dest_tmax = 0.10 * get_avg_xml_value(dest_forecast, \"temperature[@type='maximum']\")\n",
    "dest_tmin = 0.10 * get_avg_xml_value(dest_forecast, \"temperature[@type='minimum']\")\n",
    "dest_snwd = 0.10 * get_avg_xml_value(dest_forecast, \"precipitation[@type='snow']\")\n",
    "dest_liquid = 0.10 * get_avg_xml_value(dest_forecast, \"precipitation[@type='liquid']\")\n",
    "\n",
    "# This snow to liquid ratio is often assumed, however can be inaccurate.\n",
    "# It is suitable for demonstration purposes, but may need more acccurate \n",
    "# inspection in production use cases.\n",
    "snow_to_liquid_ration = 10.0\n",
    "\n",
    "origin_avg = (origin_tmax + origin_tmin) / 2\n",
    "origin_prcp = origin_liquid if origin_avg > 0 else 0\n",
    "origin_snow = 0 if origin_avg > 0 else snow_to_liquid_ration * origin_liquid\n",
    "\n",
    "dest_avg = (dest_tmax + dest_tmin) / 2\n",
    "dest_prcp = dest_liquid if dest_avg > 0 else 0\n",
    "dest_snow = 0 if dest_avg > 0 else snow_to_liquid_ration * dest_liquid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c36b5",
   "metadata": {},
   "source": [
    "Send data to the endpoint and make the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0022444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"0.6006277799606323\"\n"
     ]
    }
   ],
   "source": [
    "payload =  {\"data\": [\n",
    "    day_of_week, month, \n",
    "    carrier, \n",
    "    origin_lat, origin_lon, \n",
    "    dest_lat, dest_lon,\n",
    "    origin_tmax, origin_tmin, origin_prcp, origin_snow, origin_snwd,\n",
    "    dest_tmax, dest_tmin, dest_prcp, dest_snow, dest_snwd\n",
    "]}\n",
    "print(json.dumps(\n",
    "    pipeline_predictor.predict(payload).decode(\"utf-8\"), \n",
    "    indent=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f588cdf",
   "metadata": {},
   "source": [
    "## Cleanup resources <a class=\"anchor\" id=\"cleanup\"></a>\n",
    "Because this is a temporary project, delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4411c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscaling_client.delete_scaling_policy(\n",
    "    PolicyName=autoscaling_policy_name,\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=endpoint_resource_id,\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    ")\n",
    "inference_model_monitor.delete_monitoring_schedule()\n",
    "pipeline_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
