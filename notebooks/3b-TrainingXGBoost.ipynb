{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab00c29",
   "metadata": {},
   "source": [
    "# 3b - Training with built-in XGBoost <a class=\"anchor\" id=\"top\"></a>\n",
    "* [Introduction](#intro)\n",
    "* [Setup](#setup)\n",
    "* [Estimator creation](#estim)\n",
    "    * [Define estimator](#define)\n",
    "    * [Train estimator and tune parameters](#tune)\n",
    "* [Evaluate training result](#eval)\n",
    "* [Cleanup resources](#clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0847bc41",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "In this notebook, we will train an XGBoost model, evaluate the training performance, and output model artifacts.\n",
    "XGBoost is a regularizing gradient boosting framework with proven performance in ML competitions.\n",
    "Additionally, the algorithm has a variety of hyperparameters, which allows for signigicant gains to be had by way of tuning.\n",
    "We will be using Amazon's built-in XGBoost implementation, which integrates nicely with their hyperparameter tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54db5cde",
   "metadata": {},
   "source": [
    "## Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "First, we import Sageamker SDK dependencies as well as modules used in application below.\n",
    "We also get relevant sessions and read in local environment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd6efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import boto3\n",
    "import random\n",
    "import tarfile\n",
    "import pickle as pkl\n",
    "import datetime as dt\n",
    "import sagemaker as sm\n",
    "import sagemaker.xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "561a8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sm.Session()\n",
    "role = sm.get_execution_role()\n",
    "boto3_session = boto3.session.Session()\n",
    "now = dt.datetime.now().strftime(r\"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0667c565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boto3 session attributes.\n",
    "account = boto3_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3_session.region_name\n",
    "\n",
    "# Create clients to access S3.\n",
    "s3_client = boto3_session.client(\"s3\")\n",
    "s3_resource = boto3_session.resource(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b80379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data and model bucket names.\n",
    "with open(\"/home/ec2-user/.aiml-bb/stack-data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    data_bucket = data[\"data_bucket\"]\n",
    "    model_bucket = data[\"model_bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc09be75",
   "metadata": {},
   "source": [
    "## Estimator creation <a class=\"anchor\" id=\"estim\"></a>\n",
    "We can now create the XGBoost estimator, using Amazon's built-in implementation.\n",
    "Because the model is managed for us, there is little to do in way of setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1781ec",
   "metadata": {},
   "source": [
    "### Define estimator <a class=\"anchor\" id=\"define\"></a>\n",
    "Here we create the `Estimator` object, and all resources that are required to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8354a4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get XGBoost container image for current region.\n",
    "xgb_container_image = sm.image_uris.retrieve(\"xgboost\", region, \"latest\")\n",
    "\n",
    "# Create a unique training job name.\n",
    "training_job_name = f\"xgboost-{str(uuid.uuid4())[:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0010d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sm.inputs.TrainingInput(\n",
    "    s3_data=f\"s3://{data_bucket}/preprocessing_output/train/\", \n",
    "    content_type=\"csv\"\n",
    ")\n",
    "validation_input = sm.inputs.TrainingInput(\n",
    "    s3_data=f\"s3://{data_bucket}/preprocessing_output/validation/\",\n",
    "    content_type=\"csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec95981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator running the XGBoost container.\n",
    "xgb_estimator = sm.estimator.Estimator(\n",
    "    xgb_container_image,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.12xlarge\",\n",
    "    volume_size=50,\n",
    "    output_path=f\"s3://{model_bucket}/sagemaker-xgboost/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a91dc",
   "metadata": {},
   "source": [
    "### Train estimator and tune parameters <a class=\"anchor\" id=\"tune\"></a>\n",
    "Hyperparameters are now defined as well as valid ranges.\n",
    "We then attach a `HyperparameterTuner` and fit the tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90301ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define starting hyperparameters for the model.\n",
    "xgb_estimator.set_hyperparameters(\n",
    "    eval_metric=\"auc\",\n",
    "    objective=\"binary:logistic\",\n",
    "    max_depth=6,\n",
    "    eta=0.2,\n",
    "    alpha=2.0,\n",
    "    gamma=4,\n",
    "    min_child_weight=8,\n",
    "    subsample=0.8,\n",
    "    silent=0,\n",
    "    num_round=100,\n",
    "    early_stopping_rounds=25\n",
    ")\n",
    "# Set ranges of XGBoost hyperparameters for tuning.\n",
    "xgb_hyperparameter_ranges = {\n",
    "    \"eta\": sm.tuner.ContinuousParameter(0, 1),\n",
    "    \"alpha\": sm.tuner.ContinuousParameter(0, 3),\n",
    "    \"min_child_weight\": sm.tuner.ContinuousParameter(1, 10),\n",
    "    \"max_depth\": sm.tuner.IntegerParameter(1, 10)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ca290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................"
     ]
    }
   ],
   "source": [
    "# Create tuner and fit.\n",
    "xgb_objective_metric_name = \"validation:auc\"\n",
    "xgb_tuner = sm.tuner.HyperparameterTuner(\n",
    "    xgb_estimator,\n",
    "    xgb_objective_metric_name,\n",
    "    xgb_hyperparameter_ranges,\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=5,\n",
    "    strategy=\"Bayesian\"\n",
    ")\n",
    "xgb_tuner.fit(\n",
    "    {\"train\": train_input, \"validation\": validation_input}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d40b95",
   "metadata": {},
   "source": [
    "## Select best model <a class=\"anchor\" id=\"select-best\"></a>\n",
    "View the analytics from the tuning job and select the best model.\n",
    "We then store the best model in location that we can reference more easily in other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdb3574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View analytics on tuning job results.\n",
    "xgb_tuner_analytics = sm.HyperparameterTuningJobAnalytics(\n",
    "    xgb_tuner.describe()[\"HyperParameterTuningJobName\"]\n",
    ")\n",
    "xgb_tuner_analytics.dataframe().sort_values(\"FinalObjectiveValue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72184dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take best model and copy to location we can reference in other notebooks.\n",
    "xgb_best_training_job_name = xgb_tuner.best_training_job()\n",
    "xgb_best_training_job_key = f\"sagemaker-xgboost/{xgb_best_training_job_name}/output/model.tar.gz\"\n",
    "copy_source = {\n",
    "    \"Bucket\": model_bucket,\n",
    "    \"Key\": xgb_best_training_job_key\n",
    "}\n",
    "s3_resource.Bucket(model_bucket).copy(\n",
    "    copy_source, \n",
    "    \"sagemaker-xgboost-tuned/model.tar.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cee458f",
   "metadata": {},
   "source": [
    "## Create endpoint to test model <a class=\"anchor\" id=\"endpoint\"></a>\n",
    "To test the model, we must now create an endpoint that we can send the test data set aside during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd013ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and endpoint from best fitted estimator above.\n",
    "xgb_model = sm.model.Model(\n",
    "    image_uri=xgb_container_image,\n",
    "    model_data=f\"s3://{model_bucket}/sagemaker-xgboost-tuned/model.tar.gz\",\n",
    "    role=role\n",
    ")\n",
    "endpoint_name = f\"xgb-test-endpt-{now}\"\n",
    "xgb_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129c11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect a predictor to the endpoint for inference.\n",
    "xgb_predictor = sm.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sm_session,\n",
    "    serializer=sm.serializers.CSVSerializer(\n",
    "        content_type=\"text/csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over testing data and compute statistics.\n",
    "list_objs_response = s3_client.list_objects_v2(\n",
    "    Bucket=data_bucket, \n",
    "    Prefix=\"preprocessing_output/train\"\n",
    ")\n",
    "\n",
    "# Arrays to keep track of results.\n",
    "test_actuals = []\n",
    "test_predictions = []\n",
    "for obj in list_objs_response[\"Contents\"]:\n",
    "    \n",
    "    # Iterate over lines in object contents via stream.\n",
    "    obj_resource = s3_resource.Object(data_bucket, obj[\"Key\"])\n",
    "    for line in obj_resource.get()[\"Body\"].iter_lines():\n",
    "        target, features = line.decode(\"utf-8\").split(\",\", maxsplit=1)\n",
    "        features = features.strip()\n",
    "        prediction = xgb_predictor.predict(features)\n",
    "        \n",
    "        test_actuals.append(float(target))\n",
    "        test_predictions.append(float(prediction))\n",
    "    \n",
    "        if len(test_actuals) > 100_000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b931b74",
   "metadata": {},
   "source": [
    "## Evaluate training results <a class=\"anchor\" id=\"eval\"></a>\n",
    "Lastly, we evaluate the results of training against the testing data set.\n",
    "Note that this data set is not included in training and has never been seen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc3767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actuals = [0,0,0,1,0,0,1,1,1]\n",
    "test_predictions = [0,0,1,1,0,0,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap lists in numpy arrays for analysis.\n",
    "test_actuals_np = np.array(test_actuals)\n",
    "test_predictions_np = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87082980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics on perfomance.\n",
    "performance_statistics = {\n",
    "    \"accuracy\": metrics.accuracy_score(test_actuals_np, test_predictions_np),\n",
    "    \"precision\": metrics.precision_score(test_actuals_np, test_predictions_np),\n",
    "    \"recall\": metrics.recall_score(test_actuals_np, test_predictions_np),\n",
    "    \"f1\": metrics.f1_score(test_actuals_np, test_predictions_np),\n",
    "    \"auc\": metrics.roc_auc_score(test_actuals_np, test_predictions_np),\n",
    "}\n",
    "print(json.dumps(performance_statistics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix.\n",
    "confusion_df = pd.crosstab(\n",
    "    test_actuals_np, \n",
    "    test_predictions_np, \n",
    "    rownames=[\"Actuals\"], \n",
    "    colnames=[\"Predictions\"]\n",
    ")\n",
    "norm_confusion_df = confusion_df / confusion_df.sum(axis=1)\n",
    "\n",
    "# Show confusion matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    norm_confusion_df, \n",
    "    vmin=-1.0, vmax=1.0, annot=True, fmt=\".2f\", \n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Confusion matrix of testing results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_actuals_np, test_predictions_np)\n",
    "\n",
    "# Plot ROC matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, label='ROC')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--')\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.set_title('Receiver operating characteristic curve')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d75d49",
   "metadata": {},
   "source": [
    "## Cleanup resources <a class=\"anchor\" id=\"clean\"></a>\n",
    "Because this is a temporary project, delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc56b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
