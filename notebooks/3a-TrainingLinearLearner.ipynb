{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1ec51d",
   "metadata": {},
   "source": [
    "# 3a- Training with built-in LinearLearner <a class=\"anchor\" id=\"top\"></a>\n",
    "* [Introduction](#intro)\n",
    "* [Setup](#setup)\n",
    "* [Estimator creation](#estim)\n",
    "    * [Define estimator](#define)\n",
    "    * [Train estimator and tune parameters](#tune)\n",
    "* [Evaluate training result](#eval)\n",
    "* [Cleanup resources](#clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e2f514",
   "metadata": {},
   "source": [
    "## Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "In this notebook, we will train a Linear Learner model, evaluate the training performance, and output model artifacts.\n",
    "Linear Learner is based on logistic regression models.\n",
    "We will be using Amazon's built-in Linear Learner implementation which has an internal model jyperparameter tuning mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7923fc8",
   "metadata": {},
   "source": [
    "## Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "First, we import Sageamker SDK dependencies as well as modules used in application below.\n",
    "We also get relevant sessions and read in local environment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8553e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "import boto3\n",
    "import random\n",
    "import tarfile\n",
    "import pickle as pkl\n",
    "import datetime as dt\n",
    "import sagemaker as sm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218444f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sm.Session()\n",
    "role = sm.get_execution_role()\n",
    "boto3_session = boto3.session.Session()\n",
    "now = dt.datetime.now().strftime(r\"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c370364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get boto3 session attributes.\n",
    "account = boto3_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3_session.region_name\n",
    "\n",
    "# Create clients to access S3.\n",
    "s3_client = boto3_session.client(\"s3\")\n",
    "s3_resource = boto3_session.resource(\"s3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c65860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data and model bucket names.\n",
    "with open(\"/home/ec2-user/.aiml-bb/stack-data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    data_bucket = data[\"data_bucket\"]\n",
    "    model_bucket = data[\"model_bucket\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a5e72",
   "metadata": {},
   "source": [
    "## Estimator creation <a class=\"anchor\" id=\"estim\"></a>\n",
    "We can now create the Linear Learner estimator, using Amazon's built-in implementation.\n",
    "Because the model is managed for us, there is little to do in way of setup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767137c",
   "metadata": {},
   "source": [
    "### Define and train estimator <a class=\"anchor\" id=\"define\"></a>\n",
    "Here we create the `Estimator` object, and all resources that are required to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b630ebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 'oost container image for current region.\n",
    "ll_container_image = sm.image_uris.retrieve(\"linear-learner\", region)\n",
    "\n",
    "# Create a unique training job name.\n",
    "training_job_name = f\"'ll-{str(uuid.uuid4())[:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d96ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sm.inputs.TrainingInput(\n",
    "    s3_data=f\"s3://{data_bucket}/preprocessing_output/train/\", \n",
    "    content_type=\"text/csv\"\n",
    ")\n",
    "validation_input = sm.inputs.TrainingInput(\n",
    "    s3_data=f\"s3://{data_bucket}/preprocessing_output/validation/\",\n",
    "    content_type=\"text/csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58dc65a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator running the Linear Learner container.\n",
    "ll_estimator = sm.estimator.Estimator(\n",
    "    ll_container_image,\n",
    "    role, \n",
    "    instance_count=1, \n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    volume_size=50,\n",
    "    output_path=f\"s3://{model_bucket}/sagemaker-linear-learner/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e1d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-27 06:38:53 Starting - Starting the training job...\n",
      "2022-01-27 06:38:55 Starting - Launching requested ML instancesProfilerReport-1643265533: InProgress\n",
      "......\n",
      "2022-01-27 06:40:14 Starting - Preparing the instances for training............\n",
      "2022-01-27 06:42:15 Downloading - Downloading input data..................\n",
      "2022-01-27 06:45:27 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'predictor_type': 'binary_classifier', 'binary_classifier_model_selection_criteria': 'precision_at_target_recall'}\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Final configuration: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'precision_at_target_recall', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 WARNING 140589668607808] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Using default worker.\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Create Store: local\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7fdd2591d410>\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[0.4036352  0.326444   0.3983543  0.3487702  0.31345546 0.31570172\n",
      " 0.37910953 0.2768417  0.18809141 0.20162381 0.21395835 0.3575164\n",
      " 0.23765521 0.3551901  0.1946738  0.27101153 0.24986453 0.25143367\n",
      " 0.35698232 0.38128358 0.26132655 0.3449     0.14459334 0.15886414\n",
      " 0.27711496 0.26102972 0.14216365 0.18216142 0.1025828  0.18400961\n",
      " 0.14429207 0.13328026 0.12118915 0.09008262 0.05789924 0.03690226\n",
      " 0.11597592 0.05943808 0.0624004  0.29743752 0.19272676 0.18538181\n",
      " 0.27185535 0.47536832 0.18853861 0.31902197 0.20469038 0.14549308\n",
      " 0.21376625 0.11673577 0.1289309  0.15886413 0.08858069 0.15994523\n",
      " 0.14608952 0.09859911 0.08908422 0.07951818 0.4005445  0.31659284\n",
      " 0.27505603 0.21794495 0.30818638 0.17405385 0.17108734 0.27297467\n",
      " 0.19871055 0.20650415 0.16831589 0.20038147 0.23579475 0.165492\n",
      " 0.09491189 0.19744632 0.07780623 0.06924571 0.01348277 0.98517066\n",
      " 0.96101797 0.6935698  0.49829185 1.274551   0.90729874 0.90895694\n",
      " 0.57029235 0.4434258  0.8909365 ]\u001b[0m\n",
      "\u001b[34m<NDArray 87 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[2.04909116e-01 1.21272735e-01 1.97818205e-01 1.41727284e-01\n",
      " 1.10454559e-01 1.12272732e-01 1.74000010e-01 8.36363733e-02\n",
      " 3.67272831e-02 4.24545482e-02 4.80909161e-02 1.50454551e-01\n",
      " 6.00909144e-02 1.48090914e-01 3.94545533e-02 7.98181891e-02\n",
      " 6.69090897e-02 6.78181872e-02 1.49909094e-01 1.76545471e-01\n",
      " 7.37272799e-02 1.38000026e-01 2.13636402e-02 2.59090923e-02\n",
      " 8.38181898e-02 7.35454559e-02 2.06363630e-02 3.43636386e-02\n",
      " 1.06363650e-02 3.50909121e-02 2.12727282e-02 1.80909093e-02\n",
      " 1.49090933e-02 8.18181783e-03 3.36363679e-03 1.36363658e-03\n",
      " 1.36363655e-02 3.54545494e-03 3.90909147e-03 9.80909169e-02\n",
      " 3.86363678e-02 3.56363654e-02 8.03636536e-02 3.45000029e-01\n",
      " 3.69090959e-02 1.15000010e-01 4.38181870e-02 2.16363631e-02\n",
      " 4.80000004e-02 1.38181821e-02 1.69090927e-02 2.59090923e-02\n",
      " 7.90909212e-03 2.62727290e-02 2.18181852e-02 9.81818233e-03\n",
      " 8.00000038e-03 6.36363681e-03 2.00727299e-01 1.13000005e-01\n",
      " 8.24545622e-02 5.00000045e-02 1.06272742e-01 3.12727317e-02\n",
      " 3.01818214e-02 8.10909122e-02 4.11818214e-02 4.46363688e-02\n",
      " 2.91818194e-02 4.19090949e-02 5.90909161e-02 2.81818211e-02\n",
      " 9.09090973e-03 4.06363644e-02 6.09090971e-03 4.81818197e-03\n",
      " 1.81818163e-04 1.71137154e+00 8.29526365e-01 2.18703553e-01\n",
      " 4.50172164e-02 1.92066520e-01 1.97815573e+00 1.01902032e+00\n",
      " 1.48400858e-01 4.32973206e-02 1.07160427e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 87 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] nvidia-smi: took 0.055 seconds to run.\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[01/27/2022 06:45:33 INFO 140589668607808] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1643265933.8088164, \"EndTime\": 1643265933.8088539, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Define starting hyperparameters for the model.\n",
    "ll_estimator.set_hyperparameters(\n",
    "    predictor_type=\"binary_classifier\",\n",
    "    binary_classifier_model_selection_criteria=\"precision_at_target_recall\",\n",
    ")\n",
    "ll_estimator.fit(\n",
    "    {\"train\": train_input, \"validation\": validation_input}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afad8b",
   "metadata": {},
   "source": [
    "## Create endpoint to test model <a class=\"anchor\" id=\"endpoint\"></a>\n",
    "To test the model, we must now create an endpoint that we can send the test data set aside during preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd840bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and endpoint from best fitted estimator above.\n",
    "ll_model = sm.model.Model(\n",
    "    image_uri=ll_container_image,\n",
    "    model_data=f\"s3://{model_bucket}/sagemaker-linear-learner/output/model.tar.gz\",\n",
    "    role=role\n",
    ")\n",
    "endpoint_name = f\"ll-test-endpt-{now}\"\n",
    "ll_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6406359d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect a predictor to the endpoint for inference.\n",
    "ll_predictor = sm.predictor.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sm_session,\n",
    "    serializer=sm.serializers.CSVSerializer(\n",
    "        content_type=\"text/csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03cf347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over testing data and compute statistics.\n",
    "list_objs_response = s3_client.list_objects_v2(\n",
    "    Bucket=data_bucket, \n",
    "    Prefix=\"preprocessing_output/train\"\n",
    ")\n",
    "\n",
    "# Arrays to keep track of results.\n",
    "test_actuals = []\n",
    "test_predictions = []\n",
    "for obj in list_objs_response[\"Contents\"]:\n",
    "    \n",
    "    # Iterate over lines in object contents via stream.\n",
    "    obj_resource = s3_resource.Object(data_bucket, obj[\"Key\"])\n",
    "    for line in obj_resource.get()[\"Body\"].iter_lines():\n",
    "        target, features = line.decode(\"utf-8\").split(\",\", maxsplit=1)\n",
    "        features = features.strip()\n",
    "        prediction = ll_predictor.predict(features)\n",
    "        \n",
    "        test_actuals.append(float(target))\n",
    "        test_predictions.append(float(prediction))\n",
    "    \n",
    "        if len(test_actuals) > 100_000:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2250e76",
   "metadata": {},
   "source": [
    "## Evaluate training results <a class=\"anchor\" id=\"eval\"></a>\n",
    "Lastly, we evaluate the results of training against the testing data set.\n",
    "Note that this data set is not included in training and has never been seen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c60c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap lists in numpy arrays for analysis.\n",
    "test_actuals_np = np.array(test_actuals)\n",
    "test_predictions_np = np.array(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a73157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics on perfomance.\n",
    "performance_statistics = {\n",
    "    \"accuracy\": metrics.accuracy_score(test_actuals_np, test_predictions_np),\n",
    "    \"precision\": metrics.precision_score(test_actuals_np, test_predictions_np),\n",
    "    \"recall\": metrics.recall_score(test_actuals_np, test_predictions_np),\n",
    "    \"f1\": metrics.f1_score(test_actuals_np, test_predictions_np),\n",
    "    \"auc\": metrics.roc_auc_score(test_actuals_np, test_predictions_np),\n",
    "}\n",
    "print(json.dumps(performance_statistics, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3115204a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix.\n",
    "confusion_df = pd.crosstab(\n",
    "    test_actuals_np, \n",
    "    test_predictions_np, \n",
    "    rownames=[\"Actuals\"], \n",
    "    colnames=[\"Predictions\"]\n",
    ")\n",
    "norm_confusion_df = confusion_df / confusion_df.sum(axis=1)\n",
    "\n",
    "# Show confusion matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    norm_confusion_df, \n",
    "    vmin=-1.0, vmax=1.0, annot=True, fmt=\".2f\", \n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title(\"Confusion matrix of testing results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_actuals_np, test_predictions_np)\n",
    "\n",
    "# Plot ROC matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(fpr, tpr, label='ROC')\n",
    "ax.plot([0, 1], [0, 1], linestyle='--')\n",
    "ax.set_xlabel('False positive rate')\n",
    "ax.set_ylabel('True positive rate')\n",
    "ax.set_title('Receiver operating characteristic curve')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d800d283",
   "metadata": {},
   "source": [
    "## Cleanup resources <a class=\"anchor\" id=\"clean\"></a>\n",
    "Because this is a temporary project, delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b135e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13feacb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
